{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Epidemy(Graph):\n",
    "    '''Epidemy extends the igraph's class Graph. Ciao\n",
    "    The additional functionalities are:\n",
    "    \n",
    "    1 Built-in getters for graph metrics\n",
    "        1.1 Plotting\n",
    "            a)\n",
    "            b)\n",
    "        1.2 Metrics\n",
    "            a) distribution model\n",
    "            b) eggr\n",
    "    \n",
    "    '''\n",
    "    graph = None\n",
    "    patient_zero = None\n",
    "    sentinels = None\n",
    "    global I\n",
    "    \n",
    "    def __init__(self, graph_edge_list, patient_zero = None, sentinels = None):\n",
    "        '''The compartment label is a byte that can take values 0, 1 and 2, indicating respectivly\n",
    "        0 - Suscebtible node\n",
    "        1 - Infected node'''\n",
    "        \n",
    "        \n",
    "        self.graph = Graph.Read_Ncol(graph_edge_list, directed=False)\n",
    "        self.patient_zero = patient_zero\n",
    "        self.sentinels = sentinels\n",
    "             \n",
    "    \n",
    "    #setters  \n",
    "    def setPatientZero(self, patient_zero):\n",
    "        self.patient_zero = set(patient_zero)\n",
    "        \n",
    "    def setSentinels(self, sentinels):\n",
    "        self.sentinels = set(sentinels)\n",
    "        \n",
    "    def resetSentinels(self):\n",
    "        self.graph.vs[\"iteration\"] = np.nan\n",
    "        \n",
    "    def resetNodes(self):\n",
    "        self.graph.vs[\"compartment\"] = np.zeros(len(self.graph.vs), dtype = np.uint8)\n",
    "    \n",
    "     \n",
    "    #getters\n",
    "    def getDegreeDistribution(self):\n",
    "        x,y = np.unique(self.graph.degree(), return_counts=True)\n",
    "        print(len(self.graph.degree()))\n",
    "        return (x,y)\n",
    "    \n",
    "    def getMaxDegreeVertex(self):\n",
    "        return self.graph.vs[self.graph.degree().index(self.graph.maxdegree())]\n",
    "    \n",
    "    def getSentinelsIteration(self):\n",
    "        return [i[\"iteration\"] for i in self.graph.vs[self.sentinels]]\n",
    "    \n",
    "    def getBestVertexByCentrality(self, number):\n",
    "        aux = sorted(self.graph.degree())\n",
    "        return (aux[:number], aux[-number:], \"centrality\")\n",
    "        \n",
    "    def getBestVertexByCloseness(self, number):\n",
    "        aux = sorted(self.graph.closeness())\n",
    "        return (aux[:number], aux[-number:], \"closeness\")\n",
    "        \n",
    "    def getBestVertexByBetweennes(self, number):\n",
    "        aux = sorted(self.graph.pagerank())\n",
    "        return (aux[:number], aux[-number:], \"betweenness\")\n",
    "    \n",
    "    def getBestVertexByPagerank(self, number):\n",
    "        aux = sorted(self.graph.betweenness())\n",
    "        return (aux[:number], aux[-number:], \"pagerank\")\n",
    "            \n",
    "        \n",
    "    \n",
    "    #Epidemy Utilities\n",
    "    def printDegreeDistribution(self, loglog=False):\n",
    "        '''Prints the degree distirbution of the underlying network using a logarithmic scale'''\n",
    "        x,y = self.getDegreeDistribution()\n",
    "        if loglog:\n",
    "            plt.scatter(np.log(x), np.log(y))\n",
    "        else:\n",
    "            plt.scatter(x, y)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "    #Epidemic Models\n",
    "    def SIR(self, beta = 0.5, mu = 0.1, friend_paradox = False, verbose= False):\n",
    "        \"\"\"Simulate an epidemy outbreaks using a sir model\"\"\"\n",
    "        \n",
    "       \n",
    "        \n",
    "        if self.sentinels is None :\n",
    "            self.sentinels = set([v.index for v in np.random.choice(self.graph.vs, size=5, replace=False)])\n",
    "            print(\"No sentinels detected. Random selection: \", self.sentinels)\n",
    "            \n",
    "        if friend_paradox:\n",
    "            I = list(chain.from_iterable([self.graph.neighbors(v) for v in self.graph.vs[self.sentinels]]))\n",
    "            I = set(np.random.choice(I, size = 5, replace=False))\n",
    "        elif self.patient_zero is None:\n",
    "            I = set(np.random.choice(self.graph.vs, size= 5,replace =False))\n",
    "            print(\"No patatient zero detected. Random selection: \", self.sentinels)\n",
    "        else:\n",
    "            print self.patient_zero\n",
    "            I = self.patient_zero\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.resetNodes()\n",
    "        self.resetSentinels();\n",
    "        \n",
    "        development = []\n",
    "        if verbose:\n",
    "            print(\"Starting SIR simulation\", \"beta:\", beta, \"mu\", mu,\n",
    "              \"sentinels:\", self.sentinels, \"patient_zero: \", self.patient_zero, \"friend_paradox\", friend_paradox)\n",
    "        \n",
    "        for iteration in itertools.count():\n",
    "            if(len(I)==0):\n",
    "                print \"Epidemy is over... hurray!\"\n",
    "                break\n",
    "                \n",
    "            if verbose:   \n",
    "                print(\"Nodes in the Infected Compartment: \",len(I))\n",
    "            \n",
    "            dI = set([j for j in list(itertools.chain.from_iterable(self.graph.neighborhood(I)))\n",
    "                      if self.graph.vs[j][\"compartment\"] == 0 and np.random.random() < beta])\n",
    "            self.graph.vs[dI][\"compartment\"] = 1 \n",
    "\n",
    "\n",
    "            # Finds new removed nodes and update the status\n",
    "            dR = set([k for k in I if np.random.random() < mu])\n",
    "            self.graph.vs[dR][\"compartment\"] = 2\n",
    "            \n",
    "            self.graph.vs[dI & set(self.sentinels)][\"iteration\"] = str(iteration)\n",
    "            \n",
    "\n",
    "            I = (I | dI) - (dR)\n",
    "            \n",
    "            development +=  [len(I)]\n",
    "        return development\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orkut is a free on-line social network where users form friendship each other. Orkut also allows users form a group which other members can then join. We consider such user-defined groups as ground-truth communities. We provide the Orkut friendship social network and ground-truth communities. This data is provided by Alan Mislove et al.\n",
    "\n",
    "We regard each connected component in a group as a separate ground-truth community. We remove the ground-truth communities which have less than 3 nodes. We also provide the top 5,000 communities with highest quality which are described in our paper. As for the network, we provide the largest connected component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The graph is undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from igraph import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Epidemiology Assignment 1\n",
    "\n",
    "In this homework we are going to use a real social netwrok in order to simulate and analyze a SIR epidemy. \n",
    "\n",
    "The network that we are going to use is Orkut's social graph. I decided to use this dataset because Orkut was a community base social network. Since its connections are intrests-based, this would allow us to simulate our empidemy on a network based on a real-social interactions.\n",
    "\n",
    "Orkut's social graph is undirected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1 \n",
    " \n",
    "I decided to implement an extende class of igraph librery called Epidemy. This library is freerly aviable for download from the following link : fefefaeffez\n",
    "\n",
    "However to make things easier for the correction I included my package in this folder under the name Epidemy.py.\n",
    "\n",
    "Essentially the epidemy class implements the following functionalities:\n",
    "\n",
    "* Create Epidemy Object given a Network and an Epidemic Model\n",
    "* Simulate on the given network the given Epidemic Model\n",
    "* Get Network metrics\n",
    "    * Degree Distribution\n",
    "    * Closeness Distribution\n",
    "    * Betwenness Distribution\n",
    "    * \n",
    "\n",
    "\n",
    "In this way we can logically separate our code needed to perform some analysis from the analys itself. If the revisor is intrested in the actual implementation of the algorithm she can check the bottom of the ipython notebook to see the implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Compute and Plot a Social Network Degree [X]\n",
    "\n",
    "\n",
    "In this section we are going to load in memory Orkut and plot its degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Epidemy('dblp2.txt')\n",
    "#a.printDegreeDistribution(loglog = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SIR Epidemic Model Simulation [X]\n",
    "\n",
    "Now we are going to simulate a SIR epidemy on the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epidemic_curve = a.SIR(beta = 0.9, mu = 0.1, patient_zero = [v.index for v in a.graph.vs[-10:]])\n",
    "plt.plot(epidemic_curve)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "In this section we are going to have a better understaing of the epidemic cycle. More specifically we are going to use epdiemy sentinels, which are a random set o N nodes of the graph which will record the arrival time to them.\n",
    "Epidemic sentinels are crucial in order to understand the empidemic outbreaks, because are the one that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SIR Simulation with Static Sentinels [ ] \n",
    "\n",
    "In this subsection we are going to exploit the sentinel functionality provided by the class Epidemy. In the previous section we already run a SIR simulation using sentinels, we can retrive the information stored simply accessing the sentinel field of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.setSentinels([v.index for v in a.graph.vs[:10]])\n",
    "a.SIR(beta = 0.9, mu = 0.1, ver)             \n",
    "sb.boxplot([-1 if pd.isnull(elem) else int(elem) for elem in seq])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SIR Simulation with Dynamic Random Sentinels, Seeds and Parameters [ ]\n",
    "\n",
    "Now we want to extend the previous analysis testing different combination of \n",
    "\n",
    "* SIR parameters ($\\mu$, $\\beta$)\n",
    "* Different sentinels at each loop\n",
    "* Different number of sentinels\n",
    "* No overlap between seed and sentinels\n",
    "* Different seed at each loop\n",
    "* Multiple Seeds\n",
    "\n",
    "Most of those features are easily simulable thanks via the built-in functionalities of the epidemy class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq = []\n",
    "for i in range(2):\n",
    "    a.SIR(beta = np.random.random(), mu = np.random.random())\n",
    "    seq = seq + [np.nan if pd.isnull(i[\"iteration\"]) else int(i[\"iteration\"]) for i in a.graph.vs[a.sentinels]]\n",
    "print seq\n",
    "sb.boxplot(seq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq = [-1 if pd.isnull(elem) else int(elem) for elem in seq]\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 SIR Simulation with Static Top-Ranked Sentinels [ ]\n",
    "\n",
    "Now we want to investigate the impact of specific centrality metrics in the choice of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-126bb0f3c6b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     different we count all those combinations combination, we are going to try the those different combinations\"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m ranks = [a.getBestVertexByCentrality(top), a.getBestVertexByCloseness(top),\n\u001b[0m\u001b[1;32m      6\u001b[0m          a.getBestVertexByBetweennes(top), a.getBestVertexByPagerank(top)]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a4018f9cb330>\u001b[0m in \u001b[0;36mgetBestVertexByCloseness\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetBestVertexByCloseness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloseness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"closeness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def topRankedSentinels(var, ):\n",
    "    \"\"\" We have 8*7 = 56. Some pairs are repeted but since sentinels and seeds are conceptually\n",
    "    different we count all those combinations combination, we are going to try the those different combinations\"\"\"\n",
    "top = 10\n",
    "ranks = [a.getBestVertexByCentrality(top), a.getBestVertexByCloseness(top)\n",
    "         a.getBestVertexByBetweennes(top), a.getBestVertexByPagerank(top)]\n",
    "\n",
    "for x in ranks:\n",
    "    for y in ranks:\n",
    "        print(x[0], y[0]) \n",
    "        print(x[0], y[1])\n",
    "        print(x[1], y[0]) \n",
    "        print(x[1], y[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \"\"\"a.SIR(beta = np.random.random(), mu = np.random.random())\n",
    "    bestSeq = seq.append([i[\"iteration\"] for i in a.graph.vs[a.sentinels]])\n",
    "    a.SIR(beta = np.random.random(), mu = np.random.random())\n",
    "    worstSeq = seq.append([i[\"iteration\"] for i in a.graph.vs[a.sentinels]])\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.getBestVertexByPagerank(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'centrality')\n"
     ]
    }
   ],
   "source": [
    "print a.getBestVertexByCentrality(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 [ ]\n",
    "\n",
    "In this section we are intrested in epidemy detection with no global topology information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Friend Paradox and Local Centrality Measures [ ]\n",
    "\n",
    "In this subsection we are intrested in minimizing the **detection time** of our epidemy by the sentinels. We suppose that we do not have any information about the global topology of the graph, but only the informations about the neighbours of our seed nodes.\n",
    "\n",
    "In order to achive this result we are going to exploit the so called **friend paradox**, which we are going to discuss in section 3.2\n",
    "\n",
    "$\\mu=\\frac{\\sum_{v\\in V} d(v)}{|V|}=\\frac{2|E|}{|V|}.$\n",
    "\n",
    "$\\frac{\\sum_{v\\in V} d(v)^2}{2|E|}=\\mu + \\frac{\\sigma^2}{\\mu},$\n",
    "\n",
    "where $ {\\sigma}^{2} $ is the variance of the degrees in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq = []\n",
    "for i in range(2):\n",
    "    a.SIR(beta = 0.9, mu = 0.1, friend_paradox = True , verbose = True)\n",
    "    seq = seq + [int(i[\"iteration\"]) for i in a.graph.vs[a.sentinels]]\n",
    "sb.boxplot(np.array(seq))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Why the Friendship Paradox Works*? (and also the local centrality measures) [ ]\n",
    "\n",
    "The Friendship Paradox states that on average given a node in a graph (that we can imagine as a real person), on average its negihbours (that we can think as its friend) will have an higher degree than the node itself. Exploiting this characteristic is possible to choose from our neighbours the ones that have an higher degree randomly being sure that on average those nodes will have a higher degree, hence an higher porbability to detect the epidemy out break.\n",
    "\n",
    "We can mix this approach using a also some metrics nalysis an "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (Epidemy Class) [ ]\n",
    "\n",
    "The epidemy class is the core of this notebook. It extends the igraph graph class adding the methods required to premor an epidemy analysis smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
